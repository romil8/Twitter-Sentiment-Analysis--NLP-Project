{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraires\n",
    "import spacy\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split as tts, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>defining language of touch with different dial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>learning ab doodle all doodle should be light ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>one of the most in-your-face ex of stealing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>this would b pretty awesome if it did n't cras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>outside the waiting for the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                     tokenized_text\n",
       "0          1  defining language of touch with different dial...\n",
       "1          1  learning ab doodle all doodle should be light ...\n",
       "2          2  one of the most in-your-face ex of stealing th...\n",
       "3          0  this would b pretty awesome if it did n't cras...\n",
       "4          1                        outside the waiting for the"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and view dataset\n",
    "df = pd.read_csv('clean_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into X and Y\n",
    "X = df['tokenized_text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a tfidf vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "vector = tfidf.fit_transform(X)\n",
    "X = vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio to split into training and test set\n",
    "ratio = int(len(df)*0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and test set\n",
    "X_train = X[:ratio,:]\n",
    "X_test = X[ratio:,:]\n",
    "y_train = df['sentiment'].iloc[:ratio]\n",
    "y_test = df['sentiment'].iloc[ratio:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize MultinomialNB model\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model on training data\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction using X_test\n",
    "y_pred_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score using MultinomialNB model is 0.645.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       128\n",
      "           1       0.64      0.96      0.77      1317\n",
      "           2       0.69      0.19      0.30       699\n",
      "           3       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.65      2178\n",
      "   macro avg       0.33      0.29      0.27      2178\n",
      "weighted avg       0.61      0.65      0.56      2178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View accuracy metrics\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print('The accuracy score using MultinomialNB model is {}.'.format(round(accuracy_nb,3)))\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize LinearSVC\n",
    "svc = LinearSVC(class_weight = 'balanced', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model on training data\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction using X_test\n",
    "y_pred_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score using LinearSVC model is 0.648.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.39      0.37       128\n",
      "           1       0.73      0.76      0.74      1317\n",
      "           2       0.56      0.51      0.54       699\n",
      "           3       0.07      0.06      0.06        34\n",
      "\n",
      "    accuracy                           0.65      2178\n",
      "   macro avg       0.43      0.43      0.43      2178\n",
      "weighted avg       0.64      0.65      0.65      2178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View accuracy metrics\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print('The accuracy score using LinearSVC model is {}.'.format(round(accuracy_svc,3)))\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7506</td>\n",
       "      <td>audience q what prototyping tool do you use sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7992</td>\n",
       "      <td>at send your best amp to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247</td>\n",
       "      <td>and here 's a pic of you winning your cc cont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7688</td>\n",
       "      <td>marissa mayer phone a a cursor of physical loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3294</td>\n",
       "      <td>is even cooler than i thought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                     tokenized_text\n",
       "0      7506  audience q what prototyping tool do you use sk...\n",
       "1      7992                       at send your best amp to ...\n",
       "2       247      and here 's a pic of you winning your cc cont\n",
       "3      7688  marissa mayer phone a a cursor of physical loc...\n",
       "4      3294                      is even cooler than i thought"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load test set\n",
    "test = pd.read_csv('clean_test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null values from test\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize test\n",
    "vector_test = tfidf.transform(test['tokenized_text'])\n",
    "X_test = vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction using X_test\n",
    "y_test_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tweet_id  sentiment\n",
      "0         7506          1\n",
      "1         7992          1\n",
      "2          247          2\n",
      "3         7688          0\n",
      "4         3294          1\n",
      "5         6125          1\n",
      "6         6131          1\n",
      "7         4134          1\n",
      "8         8206          1\n",
      "9         8552          2\n",
      "10        1634          3\n",
      "11        4256          2\n",
      "12        4921          2\n",
      "13        1694          2\n",
      "14        4193          1\n",
      "15        7682          1\n",
      "16        8151          1\n",
      "17        1274          2\n",
      "18        5868          1\n",
      "19        3327          1\n",
      "20          12          1\n",
      "21        5839          1\n",
      "22        5562          2\n",
      "23        2959          2\n",
      "24        8940          0\n",
      "25        1995          1\n",
      "26         607          1\n",
      "27        7364          1\n",
      "28        8167          3\n",
      "29         681          2\n",
      "...        ...        ...\n",
      "1789      3798          2\n",
      "1790      2587          2\n",
      "1791      6709          2\n",
      "1792      1731          2\n",
      "1793      8690          2\n",
      "1794       788          2\n",
      "1795      3874          1\n",
      "1796      8575          1\n",
      "1797      8243          0\n",
      "1798       610          1\n",
      "1799      4876          1\n",
      "1800      2805          2\n",
      "1801      4884          1\n",
      "1802      5194          2\n",
      "1803      2077          1\n",
      "1804      8244          1\n",
      "1805      1782          1\n",
      "1806      8177          1\n",
      "1807      3223          1\n",
      "1808      1906          1\n",
      "1809       615          1\n",
      "1810      3765          0\n",
      "1811      5719          1\n",
      "1812      1836          2\n",
      "1813      7614          2\n",
      "1814      1550          1\n",
      "1815      1933          0\n",
      "1816      9052          0\n",
      "1817      4219          0\n",
      "1818      7210          1\n",
      "\n",
      "[1818 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Combine ID and validation Pred\n",
    "ID = pd.DataFrame(test['tweet_id'], columns =['tweet_id'])\n",
    "sentiment = pd.DataFrame(y_test_svc, columns = ['sentiment'])\n",
    "submission = ID.join(sentiment)\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save submission\n",
    "submission.to_csv('submission baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
